{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'rawpredictions/glove_0.csv',\n",
    "    'rawpredictions/glove_1.csv',\n",
    "    'rawpredictions/glove_2.csv',\n",
    "    'rawpredictions/glove_3.csv',\n",
    "    'rawpredictions/glove_4.csv',\n",
    "    'rawpredictions/glove_5.csv',\n",
    "    'rawpredictions/glove_6.csv',\n",
    "    'rawpredictions/glove_7.csv',\n",
    "    'rawpredictions/glove_8.csv',\n",
    "    'rawpredictions/glove_9.csv',\n",
    "]\n",
    "nmodels = len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 0\n",
      "loaded 1\n",
      "loaded 2\n",
      "loaded 3\n",
      "loaded 4\n",
      "loaded 5\n",
      "loaded 6\n",
      "loaded 7\n",
      "loaded 8\n",
      "loaded 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(nmodels):\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(model_names[i])\n",
    "        df['prediction_0'] = np.log(df.prediction / (1 - df.prediction))\n",
    "        df.drop('prediction', axis=1, inplace=True)\n",
    "    else:\n",
    "        df_temp = pd.read_csv(model_names[i])\n",
    "        df_temp.prediction = np.log(df_temp.prediction / (1 - df_temp.prediction))\n",
    "        df['prediction_' + str(i)] = df_temp.prediction\n",
    "    print('loaded', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['prediction'] = df.loc[:, 'prediction_0':'prediction_9'].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83814171500047585"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df.query('validation_set == 10').reordered, df.query('validation_set == 10').prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = df.loc[df.validation_set == 10, 'prediction_0':('prediction_' + str(nmodels-1))].as_matrix()\n",
    "y_train = df.loc[df.validation_set == 10, 'reordered'].as_matrix()\n",
    "X_oldtrain = df.loc[(df.validation_set > -1) & (df.validation_set < 10), 'prediction_0':('prediction_' + str(nmodels-1))].as_matrix()\n",
    "y_oldtrain = df.loc[(df.validation_set > -1) & (df.validation_set < 10), 'reordered'].as_matrix()\n",
    "X_test = df.loc[df.validation_set == -1, 'prediction_0':('prediction_' + str(nmodels-1))].as_matrix()\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_oldtrain = scaler.transform(X_oldtrain)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = df.loc[df.validation_set == 10, ['prediction_mean_1', 'prediction_mean_2']].as_matrix()\n",
    "y_train = df.loc[df.validation_set == 10, 'reordered'].as_matrix()\n",
    "X_oldtrain = df.loc[(df.validation_set > -1) & (df.validation_set < 10), ['prediction_mean_1', 'prediction_mean_2']].as_matrix()\n",
    "y_oldtrain = df.loc[(df.validation_set > -1) & (df.validation_set < 10), 'reordered'].as_matrix()\n",
    "X_test = df.loc[df.validation_set == -1, ['prediction_mean_1', 'prediction_mean_2']].as_matrix()\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_oldtrain = scaler.transform(X_oldtrain)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(include_bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = poly.fit_transform(X_train)\n",
    "X_oldtrain = poly.transform(X_oldtrain)\n",
    "X_test = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array([X_train[:,:nmodels].mean(axis=1), X_train[:,nmodels:].mean(axis=1)]).transpose()\n",
    "X_oldtrain = np.array([X_oldtrain[:,:nmodels].mean(axis=1), X_oldtrain[:,nmodels:].mean(axis=1)]).transpose()\n",
    "X_test = np.array([X_test[:,:nmodels].mean(axis=1), X_test[:,nmodels:].mean(axis=1)]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[1, 0.1, 0.001, 0.0001], class_weight=None, cv=5,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionCV(Cs=[1, .1, .001, .0001], cv=5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.61179039,  3.64322731],\n",
       "       [ 1.88120344,  1.86491656],\n",
       "       [ 0.59309404,  0.62722595],\n",
       "       ..., \n",
       "       [-0.7662714 , -1.00087056],\n",
       "       [-1.64066516, -0.29462404],\n",
       "       [-0.75973076,  0.08058768]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.001])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13686583,  0.15958202,  0.14730216,  0.11807444,  0.126903  ,\n",
       "         0.12821553,  0.13912959,  0.14703284,  0.17956682,  0.15539243,\n",
       "         0.00343299, -0.00793968,  0.01048113, -0.01995246, -0.01748667,\n",
       "        -0.00111287,  0.02039834,  0.01599443, -0.00168831, -0.00870126]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.96522015])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91099879207137691"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scores_[1.0].mean(0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88001155469461756"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.query('validation_set==10').prediction_mean_1 > 0).astype(int) == df.query('validation_set==10').reordered).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_set</th>\n",
       "      <th>validation_set</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_distinct_products</th>\n",
       "      <th>reordered</th>\n",
       "      <th>prediction_0</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>prediction_2</th>\n",
       "      <th>...</th>\n",
       "      <th>prediction_13</th>\n",
       "      <th>prediction_14</th>\n",
       "      <th>prediction_15</th>\n",
       "      <th>prediction_16</th>\n",
       "      <th>prediction_17</th>\n",
       "      <th>prediction_18</th>\n",
       "      <th>prediction_19</th>\n",
       "      <th>user_mean_proportion_products</th>\n",
       "      <th>prediction_mean_1</th>\n",
       "      <th>prediction_mean_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1187899</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.126524</td>\n",
       "      <td>2.309080</td>\n",
       "      <td>2.310206</td>\n",
       "      <td>...</td>\n",
       "      <td>2.156211</td>\n",
       "      <td>2.169453</td>\n",
       "      <td>2.092936</td>\n",
       "      <td>2.251295</td>\n",
       "      <td>2.179759</td>\n",
       "      <td>2.147182</td>\n",
       "      <td>2.605162</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>2.210116</td>\n",
       "      <td>2.245948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>363822</td>\n",
       "      <td>196</td>\n",
       "      <td>8942</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.986852</td>\n",
       "      <td>-1.124786</td>\n",
       "      <td>-1.128720</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.220835</td>\n",
       "      <td>-0.908814</td>\n",
       "      <td>-1.182434</td>\n",
       "      <td>-1.210910</td>\n",
       "      <td>-1.143323</td>\n",
       "      <td>-1.347630</td>\n",
       "      <td>-1.266388</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>-1.088746</td>\n",
       "      <td>-1.179716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1071098</td>\n",
       "      <td>196</td>\n",
       "      <td>11192</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.124843</td>\n",
       "      <td>-2.137244</td>\n",
       "      <td>-1.759599</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.395121</td>\n",
       "      <td>-2.205188</td>\n",
       "      <td>-2.424759</td>\n",
       "      <td>-2.058052</td>\n",
       "      <td>-2.445142</td>\n",
       "      <td>-2.292393</td>\n",
       "      <td>-2.425807</td>\n",
       "      <td>0.247104</td>\n",
       "      <td>-2.185613</td>\n",
       "      <td>-2.386210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1339982</td>\n",
       "      <td>196</td>\n",
       "      <td>12100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581615</td>\n",
       "      <td>0.859751</td>\n",
       "      <td>0.463173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790328</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>0.578848</td>\n",
       "      <td>0.785813</td>\n",
       "      <td>0.602138</td>\n",
       "      <td>0.770129</td>\n",
       "      <td>0.211298</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.600398</td>\n",
       "      <td>0.598871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391840</td>\n",
       "      <td>196</td>\n",
       "      <td>24280</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.326132</td>\n",
       "      <td>-3.232276</td>\n",
       "      <td>-3.318604</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.546408</td>\n",
       "      <td>-3.401035</td>\n",
       "      <td>-3.542811</td>\n",
       "      <td>-3.161018</td>\n",
       "      <td>-3.662535</td>\n",
       "      <td>-3.210860</td>\n",
       "      <td>-3.288684</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>-3.349844</td>\n",
       "      <td>-3.372631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1288958</td>\n",
       "      <td>196</td>\n",
       "      <td>25303</td>\n",
       "      <td>141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.729874</td>\n",
       "      <td>-0.891646</td>\n",
       "      <td>-0.902179</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.049538</td>\n",
       "      <td>-0.790003</td>\n",
       "      <td>-0.905433</td>\n",
       "      <td>-0.856741</td>\n",
       "      <td>-0.522171</td>\n",
       "      <td>-1.068237</td>\n",
       "      <td>-1.080593</td>\n",
       "      <td>0.216706</td>\n",
       "      <td>-0.933019</td>\n",
       "      <td>-0.854929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2644818</td>\n",
       "      <td>196</td>\n",
       "      <td>26923</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.617576</td>\n",
       "      <td>-2.524278</td>\n",
       "      <td>-2.629315</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.518082</td>\n",
       "      <td>-2.519861</td>\n",
       "      <td>-2.586874</td>\n",
       "      <td>-2.378808</td>\n",
       "      <td>-2.499528</td>\n",
       "      <td>-2.315845</td>\n",
       "      <td>-2.370624</td>\n",
       "      <td>0.168831</td>\n",
       "      <td>-2.613038</td>\n",
       "      <td>-2.495566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>431927</td>\n",
       "      <td>196</td>\n",
       "      <td>33574</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.300373</td>\n",
       "      <td>1.654618</td>\n",
       "      <td>1.519326</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606295</td>\n",
       "      <td>1.378853</td>\n",
       "      <td>1.499313</td>\n",
       "      <td>1.350047</td>\n",
       "      <td>1.393831</td>\n",
       "      <td>1.518397</td>\n",
       "      <td>1.814141</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>1.500460</td>\n",
       "      <td>1.525914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3254668</td>\n",
       "      <td>196</td>\n",
       "      <td>34207</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.462210</td>\n",
       "      <td>-0.244321</td>\n",
       "      <td>-0.136170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518416</td>\n",
       "      <td>-0.080682</td>\n",
       "      <td>-0.168282</td>\n",
       "      <td>0.033417</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>-0.199117</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.235748</td>\n",
       "      <td>-0.090234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3144266</td>\n",
       "      <td>196</td>\n",
       "      <td>42970</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.684939</td>\n",
       "      <td>-0.900526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.940067</td>\n",
       "      <td>-1.010225</td>\n",
       "      <td>-0.842308</td>\n",
       "      <td>-1.053341</td>\n",
       "      <td>-0.969800</td>\n",
       "      <td>-1.168491</td>\n",
       "      <td>-0.963841</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.752590</td>\n",
       "      <td>-1.015114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  eval_set  validation_set  order_id  product_id  user_id  \\\n",
       "0    train            10.0   1187899         196        1   \n",
       "1     test            -1.0    363822         196     8942   \n",
       "2    train             3.0   1071098         196    11192   \n",
       "3    train             8.0   1339982         196    12100   \n",
       "4     test            -1.0    391840         196    24280   \n",
       "5    train             4.0   1288958         196    25303   \n",
       "6    train             8.0   2644818         196    26923   \n",
       "7    train             1.0    431927         196    33574   \n",
       "8     test            -1.0   3254668         196    34207   \n",
       "9     test            -1.0   3144266         196    42970   \n",
       "\n",
       "   user_distinct_products  reordered  prediction_0  prediction_1  \\\n",
       "0                      18        1.0      2.126524      2.309080   \n",
       "1                      38        0.0     -0.986852     -1.124786   \n",
       "2                      37        0.0     -2.124843     -2.137244   \n",
       "3                       4        1.0      0.581615      0.859751   \n",
       "4                      14        0.0     -3.326132     -3.232276   \n",
       "5                     141        0.0     -0.729874     -0.891646   \n",
       "6                      21        0.0     -2.617576     -2.524278   \n",
       "7                      16        1.0      1.300373      1.654618   \n",
       "8                       4        0.0     -0.462210     -0.244321   \n",
       "9                      12        0.0     -0.535354     -0.684939   \n",
       "\n",
       "   prediction_2        ...          prediction_13  prediction_14  \\\n",
       "0      2.310206        ...               2.156211       2.169453   \n",
       "1     -1.128720        ...              -1.220835      -0.908814   \n",
       "2     -1.759599        ...              -2.395121      -2.205188   \n",
       "3      0.463173        ...               0.790328       0.521644   \n",
       "4     -3.318604        ...              -3.546408      -3.401035   \n",
       "5     -0.902179        ...              -1.049538      -0.790003   \n",
       "6     -2.629315        ...              -2.518082      -2.519861   \n",
       "7      1.519326        ...               1.606295       1.378853   \n",
       "8     -0.136170        ...              -0.518416      -0.080682   \n",
       "9     -0.900526        ...              -0.940067      -1.010225   \n",
       "\n",
       "   prediction_15  prediction_16  prediction_17  prediction_18  prediction_19  \\\n",
       "0       2.092936       2.251295       2.179759       2.147182       2.605162   \n",
       "1      -1.182434      -1.210910      -1.143323      -1.347630      -1.266388   \n",
       "2      -2.424759      -2.058052      -2.445142      -2.292393      -2.425807   \n",
       "3       0.578848       0.785813       0.602138       0.770129       0.211298   \n",
       "4      -3.542811      -3.161018      -3.662535      -3.210860      -3.288684   \n",
       "5      -0.905433      -0.856741      -0.522171      -1.068237      -1.080593   \n",
       "6      -2.586874      -2.378808      -2.499528      -2.315845      -2.370624   \n",
       "7       1.499313       1.350047       1.393831       1.518397       1.814141   \n",
       "8      -0.168282       0.033417       0.036424       0.026860      -0.199117   \n",
       "9      -0.842308      -1.053341      -0.969800      -1.168491      -0.963841   \n",
       "\n",
       "   user_mean_proportion_products  prediction_mean_1  prediction_mean_2  \n",
       "0                       0.327778           2.210116           2.245948  \n",
       "1                       0.368421          -1.088746          -1.179716  \n",
       "2                       0.247104          -2.185613          -2.386210  \n",
       "3                       0.678571           0.600398           0.598871  \n",
       "4                       0.107143          -3.349844          -3.372631  \n",
       "5                       0.216706          -0.933019          -0.854929  \n",
       "6                       0.168831          -2.613038          -2.495566  \n",
       "7                       0.218750           1.500460           1.525914  \n",
       "8                       0.416667          -0.235748          -0.090234  \n",
       "9                       0.444444          -0.752590          -1.015114  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['model_prediction'] = 0\n",
    "#df.loc[df.validation_set == 10, 'model_prediction'] = model.decision_function(X_train)\n",
    "#df.loc[(df.validation_set > -1) & (df.validation_set < 10), 'model_prediction'] = model.decision_function(X_oldtrain)\n",
    "#df.loc[df.validation_set == -1, 'model_prediction'] = model.decision_function(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['model_prob'] = 0\n",
    "#df.loc[df.validation_set == 10, 'model_prob'] = model.predict_proba(X_train)[:,1]\n",
    "#df.loc[(df.validation_set > -1) & (df.validation_set < 10), 'model_prob'] = model.predict_proba(X_oldtrain)[:,1]\n",
    "#df.loc[df.validation_set == -1, 'model_prob'] = model.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['user_ump_logit'] = np.log((.01 + .98 * df.user_mean_proportion_products) / (1 - (.01 + .98 * df.user_mean_proportion_products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['prediction_avg'] = df.loc[:, 'prediction_0':'prediction_9'].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['prob'] = 1.0 / (1 + np.exp(-df.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_set</th>\n",
       "      <th>validation_set</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_distinct_products</th>\n",
       "      <th>reordered</th>\n",
       "      <th>prediction_0</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>prediction_2</th>\n",
       "      <th>prediction_3</th>\n",
       "      <th>prediction_4</th>\n",
       "      <th>prediction_5</th>\n",
       "      <th>prediction_6</th>\n",
       "      <th>prediction_7</th>\n",
       "      <th>prediction_8</th>\n",
       "      <th>prediction_9</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1187899</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.126524</td>\n",
       "      <td>2.309080</td>\n",
       "      <td>2.310206</td>\n",
       "      <td>2.260471</td>\n",
       "      <td>2.163989</td>\n",
       "      <td>2.294375</td>\n",
       "      <td>2.104397</td>\n",
       "      <td>2.265535</td>\n",
       "      <td>2.042809</td>\n",
       "      <td>2.223769</td>\n",
       "      <td>2.210116</td>\n",
       "      <td>0.901154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>363822</td>\n",
       "      <td>196</td>\n",
       "      <td>8942</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.986852</td>\n",
       "      <td>-1.124786</td>\n",
       "      <td>-1.128720</td>\n",
       "      <td>-1.094986</td>\n",
       "      <td>-1.178340</td>\n",
       "      <td>-0.954015</td>\n",
       "      <td>-1.037039</td>\n",
       "      <td>-1.141195</td>\n",
       "      <td>-1.245290</td>\n",
       "      <td>-0.996234</td>\n",
       "      <td>-1.088746</td>\n",
       "      <td>0.251855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1071098</td>\n",
       "      <td>196</td>\n",
       "      <td>11192</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.124843</td>\n",
       "      <td>-2.137244</td>\n",
       "      <td>-1.759599</td>\n",
       "      <td>-2.054594</td>\n",
       "      <td>-2.436596</td>\n",
       "      <td>-2.329345</td>\n",
       "      <td>-2.357051</td>\n",
       "      <td>-2.352092</td>\n",
       "      <td>-2.232696</td>\n",
       "      <td>-2.072072</td>\n",
       "      <td>-2.185613</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1339982</td>\n",
       "      <td>196</td>\n",
       "      <td>12100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581615</td>\n",
       "      <td>0.859751</td>\n",
       "      <td>0.463173</td>\n",
       "      <td>0.467443</td>\n",
       "      <td>0.696789</td>\n",
       "      <td>0.454466</td>\n",
       "      <td>0.809707</td>\n",
       "      <td>0.330569</td>\n",
       "      <td>0.813737</td>\n",
       "      <td>0.526730</td>\n",
       "      <td>0.600398</td>\n",
       "      <td>0.645747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391840</td>\n",
       "      <td>196</td>\n",
       "      <td>24280</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.326132</td>\n",
       "      <td>-3.232276</td>\n",
       "      <td>-3.318604</td>\n",
       "      <td>-2.899490</td>\n",
       "      <td>-3.605042</td>\n",
       "      <td>-3.493843</td>\n",
       "      <td>-4.063761</td>\n",
       "      <td>-3.115214</td>\n",
       "      <td>-3.414773</td>\n",
       "      <td>-3.029308</td>\n",
       "      <td>-3.349844</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eval_set  validation_set  order_id  product_id  user_id  \\\n",
       "0    train            10.0   1187899         196        1   \n",
       "1     test            -1.0    363822         196     8942   \n",
       "2    train             3.0   1071098         196    11192   \n",
       "3    train             8.0   1339982         196    12100   \n",
       "4     test            -1.0    391840         196    24280   \n",
       "\n",
       "   user_distinct_products  reordered  prediction_0  prediction_1  \\\n",
       "0                      18        1.0      2.126524      2.309080   \n",
       "1                      38        0.0     -0.986852     -1.124786   \n",
       "2                      37        0.0     -2.124843     -2.137244   \n",
       "3                       4        1.0      0.581615      0.859751   \n",
       "4                      14        0.0     -3.326132     -3.232276   \n",
       "\n",
       "   prediction_2  prediction_3  prediction_4  prediction_5  prediction_6  \\\n",
       "0      2.310206      2.260471      2.163989      2.294375      2.104397   \n",
       "1     -1.128720     -1.094986     -1.178340     -0.954015     -1.037039   \n",
       "2     -1.759599     -2.054594     -2.436596     -2.329345     -2.357051   \n",
       "3      0.463173      0.467443      0.696789      0.454466      0.809707   \n",
       "4     -3.318604     -2.899490     -3.605042     -3.493843     -4.063761   \n",
       "\n",
       "   prediction_7  prediction_8  prediction_9  prediction      prob  \n",
       "0      2.265535      2.042809      2.223769    2.210116  0.901154  \n",
       "1     -1.141195     -1.245290     -0.996234   -1.088746  0.251855  \n",
       "2     -2.352092     -2.232696     -2.072072   -2.185613  0.101050  \n",
       "3      0.330569      0.813737      0.526730    0.600398  0.645747  \n",
       "4     -3.115214     -3.414773     -3.029308   -3.349844  0.033900  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['p_not'] = 1 - df.model_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "none_df = pd.read_csv('rawpredictions/nones.csv')\n",
    "none_df['none_prob'] = none_df.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(none_df[['user_id', 'none_prob']], on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = df.query('user_id == 10')['model_prob'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noneprob = df.query('user_id == 10')['none_prob'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.065092411300815778"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_df.none_prob.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041714959094898862"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_pnot = np.prod(1-probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_none = 0\n",
    "newprobs = probs.copy()\n",
    "while extra_none + (1-extra_none) * np.prod(1-newprobs) < noneprob:\n",
    "    extra_none = extra_none + .0001\n",
    "    newprobs = np.minimum(probs / (1 - extra_none), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024599999999999907"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = newprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nsamples = 100000\n",
    "samples = (np.random.rand(nsamples, probs.shape[0]) < probs * np.ones((nsamples, probs.shape[0]))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples[:np.random.binomial(nsamples, extra_none),:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = np.concatenate((samples, (samples.sum(1) == 0).astype(int).reshape((nsamples, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 19)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sums = samples.sum(1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = np.zeros((probs.shape[0] + 1, probs.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(nsamples):\n",
    "    P[:, sums[i]] = P[:, sums[i]] + samples[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = P / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.zeros(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[1]):\n",
    "        W[i, j] = 1.0 / (i + j + 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = np.dot(P, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = P.shape[0]\n",
    "expectedF1s = np.zeros((m))\n",
    "for k in range(m):\n",
    "    f = F[:,k]\n",
    "    h = np.zeros((m))\n",
    "    h[np.flip(np.argsort(f), axis=0)[:(k+1)]] = 1\n",
    "    expectedF1s[k] = 2 * np.dot(h, f)\n",
    "k = np.argmax(expectedF1s)\n",
    "expF1 = expectedF1s[k]\n",
    "f = F[:,k]\n",
    "prediction = np.zeros((m))\n",
    "prediction[np.flip(np.argsort(f), axis=0)[:(k+1)]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GFM(df, nsamples=10000):\n",
    "    probs = df['prob'].values\n",
    "    noneprob = df['none_prob'].values[0]\n",
    "    extra_none = 0\n",
    "    newprobs = probs.copy()\n",
    "    while extra_none + (1-extra_none) * np.prod(1-newprobs) < noneprob:\n",
    "        extra_none = extra_none + .0001\n",
    "        newprobs = np.minimum(probs / (1 - extra_none), 1)\n",
    "    probs = newprobs\n",
    "    samples = (np.random.rand(nsamples, probs.shape[0]) < probs * np.ones((nsamples, probs.shape[0]))).astype(int)\n",
    "    samples[:np.random.binomial(nsamples, extra_none),:] = 0\n",
    "    samples = np.concatenate((samples, (samples.sum(1) == 0).astype(int).reshape((nsamples, 1))), axis=1)\n",
    "    sums = samples.sum(1) - 1\n",
    "    P = np.zeros((probs.shape[0] + 1, probs.shape[0] + 1))\n",
    "    for i in range(nsamples):\n",
    "        P[:, sums[i]] = P[:, sums[i]] + samples[i, :]\n",
    "    P = P / nsamples\n",
    "    W = np.zeros(P.shape)\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            W[i, j] = 1.0 / (i + j + 2.0)\n",
    "    F = np.dot(P, W)\n",
    "    m = P.shape[0]\n",
    "    expectedF1s = np.zeros((m))\n",
    "    for k in range(m):\n",
    "        f = F[:,k]\n",
    "        h = np.zeros((m))\n",
    "        h[np.flip(np.argsort(f), axis=0)[:(k+1)]] = 1\n",
    "        expectedF1s[k] = 2 * np.dot(h, f)\n",
    "    k = np.argmax(expectedF1s)\n",
    "    expF1 = expectedF1s[k]\n",
    "    f = F[:,k]\n",
    "    prediction = np.zeros((m))\n",
    "    prediction[np.flip(np.argsort(f), axis=0)[:(k+1)]] = 1\n",
    "    df['prediction'] = prediction[:-1]\n",
    "    df['putnone'] = prediction[-1]\n",
    "    df['expF1'] = expF1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = df.query('validation_set==10').loc[:, ['user_id', 'product_id', 'order_id', 'prob', 'none_prob', 'reordered']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765057, 6)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 33min 39s, sys: 5min 17s, total: 3h 38min 56s\n",
      "Wall time: 21min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = test_df.groupby('user_id').apply(GFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gfm_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gfm_df['hit'] = gfm_df.prediction * gfm_df.reordered\n",
    "gfm_df_agg = gfm_df.groupby('user_id').agg({'reordered': np.sum,\n",
    "                                    'prediction': np.sum,\n",
    "                                    'hit': np.sum,\n",
    "                               'expF1': np.mean,\n",
    "                               'putnone': np.mean})\n",
    "gfm_df_agg['truenone'] = (gfm_df_agg.reordered == 0)\n",
    "gfm_df_agg.putnone = gfm_df_agg.putnone.astype(bool)\n",
    "gfm_df_agg['r'] = gfm_df_agg.reordered\n",
    "gfm_df_agg['p'] = gfm_df_agg.prediction\n",
    "gfm_df_agg['h'] = gfm_df_agg.hit\n",
    "gfm_df_agg.loc[gfm_df_agg.putnone & gfm_df_agg.truenone, \"h\"] = 1\n",
    "gfm_df_agg.loc[gfm_df_agg.putnone, 'p'] = gfm_df_agg.loc[gfm_df_agg.putnone, 'p'] + 1\n",
    "gfm_df_agg.loc[gfm_df_agg.truenone, 'r'] = gfm_df_agg.loc[gfm_df_agg.truenone, 'r'] + 1\n",
    "gfm_df_agg['precision'] = (gfm_df_agg['h']) / (gfm_df_agg['p'])\n",
    "gfm_df_agg['recall'] = (gfm_df_agg['h']) / (gfm_df_agg['r'])\n",
    "gfm_df_agg['f1'] = 2 * gfm_df_agg['precision'] * gfm_df_agg['recall'] / (gfm_df_agg['precision'] + gfm_df_agg['recall'] + .000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39740466341362979"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfm_df_agg.f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40801646884077508"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfm_df_agg.expF1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gfm_df_agg.putnone = gfm_df_agg.putnone.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reordered    0.594576\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.groupby('user_id').agg({'reordered': np.sum}) > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reorder cutoff: (-1.203125, -0.062500000000000111)\n",
      "best none cutoff: (0.25625000000000003, -0.94843750000000016)\n",
      "best f1: 0.40753730298\n"
     ]
    }
   ],
   "source": [
    "threshold_df = df.loc[df.eval_set == 'train', ['user_id', 'user_distinct_products', 'user_mean_proportion_products', 'user_ump_logit', 'model_prediction', 'p_not', 'reordered']].copy()\n",
    "\n",
    "guess = [-.8, -.1, .4, -1.0]\n",
    "width = np.array([.2, .1, .2, .1])\n",
    "best_reorder_cutoff = (0, 0)\n",
    "best_none_cutoff = (0, 0)\n",
    "best_cutoff_f1 = 0\n",
    "for i in range(4):\n",
    "    for reorder_cutoff in [(x,y) for x in np.arange(guess[0]-4*width[0], guess[0]+4*width[0], width[0]) for y in np.arange(guess[1]-4*width[1], guess[1]+4*width[1], width[1])]:\n",
    "        threshold_df['reorder_cutoff'] = reorder_cutoff[0] + reorder_cutoff[1] * np.log(threshold_df.user_distinct_products)\n",
    "        threshold_df.loc[:,'prediction'] = 1 * (threshold_df['model_prediction'] > threshold_df.reorder_cutoff)\n",
    "        threshold_df['hit'] = (threshold_df.reordered * threshold_df.prediction)\n",
    "        threshold_df_agg = threshold_df.groupby(\"user_id\").agg({'reordered': np.sum,\n",
    "                                                          'prediction': np.sum,\n",
    "                                                          'hit': np.sum,\n",
    "                                                              'user_distinct_products': np.mean,\n",
    "                                                             'p_not': np.prod})\n",
    "        for none_cutoff in [(x,y) for x in np.arange(guess[2]-4*width[2], guess[2]+4*width[2], width[2]) for y in np.arange(guess[3]-4*width[3], guess[3]+4*width[3], width[3])]:\n",
    "            threshold_df_agg['none_cutoff'] = 1.0 / (1 + np.exp(-none_cutoff[0] - none_cutoff[1] * np.log(threshold_df_agg.user_distinct_products)))\n",
    "            threshold_df_agg['putnone'] = (threshold_df_agg.p_not > threshold_df_agg.none_cutoff) | (threshold_df_agg.prediction == 0)\n",
    "            threshold_df_agg['truenone'] = (threshold_df_agg.reordered == 0)\n",
    "            threshold_df_agg['r'] = threshold_df_agg.reordered\n",
    "            threshold_df_agg['p'] = threshold_df_agg.prediction\n",
    "            threshold_df_agg['h'] = threshold_df_agg.hit\n",
    "            threshold_df_agg.loc[threshold_df_agg.putnone & threshold_df_agg.truenone, \"h\"] = 1\n",
    "            threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] = threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] + 1\n",
    "            threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] = threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] + 1\n",
    "            threshold_df_agg['precision'] = (threshold_df_agg['h']) / (threshold_df_agg['p'])\n",
    "            threshold_df_agg['recall'] = (threshold_df_agg['h']) / (threshold_df_agg['r'])\n",
    "            threshold_df_agg['f1'] = 2 * threshold_df_agg['precision'] * threshold_df_agg['recall'] / (threshold_df_agg['precision'] + threshold_df_agg['recall'] + .000001)\n",
    "            if threshold_df_agg['f1'].mean() > best_cutoff_f1:\n",
    "                best_cutoff_f1 = threshold_df_agg['f1'].mean()\n",
    "                best_reorder_cutoff = reorder_cutoff\n",
    "                best_none_cutoff = none_cutoff\n",
    "    guess = [best_reorder_cutoff[0], best_reorder_cutoff[1], best_none_cutoff[0], best_none_cutoff[1]]\n",
    "    width = width / 4\n",
    "print(\"best reorder cutoff:\", best_reorder_cutoff)\n",
    "print(\"best none cutoff:\", best_none_cutoff)\n",
    "print(\"best f1:\", best_cutoff_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_reorder_cutoff = (-1.203125, -0.062500000000000111)\n",
    "best_none_cutoff = (0.25625000000000003, -0.94843750000000016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_numeric_gradient(objFun, params, step=.05):\n",
    "    gradient = []\n",
    "    for i in range(len(params)):\n",
    "        p1 = params.copy()\n",
    "        p1[i] = p1[i] - step/2\n",
    "        p2 = params.copy()\n",
    "        p2[i] = p2[i] + step/2\n",
    "        gradient.append((objFun(p2)-objFun(p1))/step)\n",
    "    return np.array(gradient)\n",
    "\n",
    "def gradient_ascent(objFun, starting_params, alpha=.1, nrounds=30):\n",
    "    params = np.array(starting_params)\n",
    "    for i in range(nrounds):\n",
    "        print(objFun(params))\n",
    "        gradient = evaluate_numeric_gradient(objFun, params)\n",
    "        print(params, gradient)\n",
    "        params = params + alpha*gradient\n",
    "    return params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_distinct_orders(params):\n",
    "    threshold_df['reorder_cutoff'] = params[0] + params[1] * np.log(threshold_df.user_distinct_products)\n",
    "    threshold_df['prediction'] = 1 * (threshold_df['model_prediction'] > threshold_df.reorder_cutoff)\n",
    "    threshold_df['hit'] = (threshold_df.reordered * threshold_df.prediction)\n",
    "    threshold_df_agg = threshold_df.groupby(\"user_id\").agg({'reordered': np.sum,\n",
    "                                                      'prediction': np.sum,\n",
    "                                                      'hit': np.sum,\n",
    "                                                        'user_ump_logit': np.mean,\n",
    "                                                            'user_mean_proportion_products': np.mean,\n",
    "                                                        'user_distinct_products': np.mean,\n",
    "                                                         'p_not': np.prod})\n",
    "    threshold_df_agg['none_cutoff'] = 1.0 / (1 + np.exp(-params[2] - params[3] * np.log(threshold_df.user_distinct_products)))\n",
    "    threshold_df_agg['putnone'] = (threshold_df_agg.p_not > threshold_df_agg.none_cutoff) | (threshold_df_agg.prediction == 0)\n",
    "    threshold_df_agg['truenone'] = (threshold_df_agg.reordered == 0)\n",
    "    threshold_df_agg['r'] = threshold_df_agg.reordered\n",
    "    threshold_df_agg['p'] = threshold_df_agg.prediction\n",
    "    threshold_df_agg['h'] = threshold_df_agg.hit\n",
    "    threshold_df_agg.loc[threshold_df_agg.putnone & threshold_df_agg.truenone, \"h\"] = 1\n",
    "    threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] = threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] + 1\n",
    "    threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] = threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] + 1\n",
    "    threshold_df_agg['precision'] = (threshold_df_agg['h']) / (threshold_df_agg['p'])\n",
    "    threshold_df_agg['recall'] = (threshold_df_agg['h']) / (threshold_df_agg['r'])\n",
    "    threshold_df_agg['f1'] = 2 * threshold_df_agg['precision'] * threshold_df_agg['recall'] / (threshold_df_agg['precision'] + threshold_df_agg['recall'] + .000001)\n",
    "    return threshold_df_agg['f1'].mean()\n",
    "\n",
    "def f1_mean_orders(params):\n",
    "    threshold_df['reorder_cutoff'] = params[0] + params[1] * threshold_df.user_ump_logit\n",
    "    threshold_df['prediction'] = 1 * (threshold_df['model_prediction'] > threshold_df.reorder_cutoff)\n",
    "    threshold_df['hit'] = (threshold_df.reordered * threshold_df.prediction)\n",
    "    threshold_df_agg = threshold_df.groupby(\"user_id\").agg({'reordered': np.sum,\n",
    "                                                      'prediction': np.sum,\n",
    "                                                      'hit': np.sum,\n",
    "                                                        'user_ump_logit': np.mean,\n",
    "                                                            'user_mean_proportion_products': np.mean,\n",
    "                                                        'user_distinct_products': np.mean,\n",
    "                                                         'p_not': np.prod})\n",
    "    threshold_df_agg['none_cutoff'] = 1.0 / (1 + np.exp(-params[2] - params[3] * threshold_df.user_ump_logit))\n",
    "    threshold_df_agg['putnone'] = (threshold_df_agg.p_not > threshold_df_agg.none_cutoff) | (threshold_df_agg.prediction == 0)\n",
    "    threshold_df_agg['truenone'] = (threshold_df_agg.reordered == 0)\n",
    "    threshold_df_agg['r'] = threshold_df_agg.reordered\n",
    "    threshold_df_agg['p'] = threshold_df_agg.prediction\n",
    "    threshold_df_agg['h'] = threshold_df_agg.hit\n",
    "    threshold_df_agg.loc[threshold_df_agg.putnone & threshold_df_agg.truenone, \"h\"] = 1\n",
    "    threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] = threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] + 1\n",
    "    threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] = threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] + 1\n",
    "    threshold_df_agg['precision'] = (threshold_df_agg['h']) / (threshold_df_agg['p'])\n",
    "    threshold_df_agg['recall'] = (threshold_df_agg['h']) / (threshold_df_agg['r'])\n",
    "    threshold_df_agg['f1'] = 2 * threshold_df_agg['precision'] * threshold_df_agg['recall'] / (threshold_df_agg['precision'] + threshold_df_agg['recall'] + .000001)\n",
    "    return threshold_df_agg['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/alex/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#threshold_df = df.loc[df.eval_set == 'train', ['user_id', 'user_distinct_products', 'user_mean_proportion_products', 'user_ump_logit', 'model_prediction', 'p_not', 'reordered']].copy()\n",
    "#threshold_df['user_distinct_products_log_scaled'] = StandardScaler().fit_transform(np.log(threshold_df.user_distinct_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/alex/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#threshold_df['user_ump_scaled'] = StandardScaler().fit_transform(threshold_df.user_ump_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [-1.52396524, 0,  -1, 0]\n",
    "threshold_df['reorder_cutoff'] = params[0] + params[1] * np.log(threshold_df.user_distinct_products)\n",
    "threshold_df['prediction'] = 1 * (threshold_df['model_prediction'] > threshold_df.reorder_cutoff)\n",
    "threshold_df['hit'] = (threshold_df.reordered * threshold_df.prediction)\n",
    "threshold_df_agg = threshold_df.groupby(\"user_id\").agg({'reordered': np.sum,\n",
    "                                                  'prediction': np.sum,\n",
    "                                                  'hit': np.sum,\n",
    "                                                    'user_ump_logit': np.mean,\n",
    "                                                        'user_mean_proportion_products': np.mean,\n",
    "                                                    'user_distinct_products': np.mean,\n",
    "                                                     'p_not': np.prod})\n",
    "threshold_df_agg['none_cutoff'] = 1.0 / (1 + np.exp(-params[2] - params[3] * np.log(threshold_df.user_distinct_products)))\n",
    "threshold_df_agg['putnone'] = (threshold_df_agg.p_not > threshold_df_agg.none_cutoff) | (threshold_df_agg.prediction == 0)\n",
    "threshold_df_agg['truenone'] = (threshold_df_agg.reordered == 0)\n",
    "threshold_df_agg['r'] = threshold_df_agg.reordered\n",
    "threshold_df_agg['p'] = threshold_df_agg.prediction\n",
    "threshold_df_agg['h'] = threshold_df_agg.hit\n",
    "threshold_df_agg.loc[threshold_df_agg.putnone & threshold_df_agg.truenone, \"h\"] = 1\n",
    "threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] = threshold_df_agg.loc[threshold_df_agg.putnone, 'p'] + 1\n",
    "threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] = threshold_df_agg.loc[threshold_df_agg.truenone, 'r'] + 1\n",
    "threshold_df_agg['precision'] = (threshold_df_agg['h']) / (threshold_df_agg['p'])\n",
    "threshold_df_agg['recall'] = (threshold_df_agg['h']) / (threshold_df_agg['r'])\n",
    "threshold_df_agg['f1'] = 2 * threshold_df_agg['precision'] * threshold_df_agg['recall'] / (threshold_df_agg['precision'] + threshold_df_agg['recall'] + .000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4057918136201808"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df_agg.f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18316693472074724, 1.6755651425746639e-90)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(threshold_df_agg.user_mean_proportion_products, threshold_df_agg.f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11697bfd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1167f6240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(pd.DataFrame({'dp': np.log(threshold_df_agg.user_distinct_products),\n",
    "               'f1':threshold_df_agg.f1,\n",
    "              'mp': threshold_df_agg.user_ump_logit})\n",
    " #.query('f1 < .999 and f1 > 0.0')\n",
    " #.eval('f1 = log(f1 / (1-f1))', inplace=False)\n",
    " .plot.scatter(x='mp', y='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1df = pd.DataFrame({'dp': np.log(threshold_df_agg.user_distinct_products),\n",
    "               'f1':threshold_df_agg.f1,\n",
    "              'mp': threshold_df_agg.user_ump_logit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1x = f1df[['dp', 'mp']].values\n",
    "f1y = f1df['f1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1x = f1scale.fit_transform(f1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1model = LinearRegression()\n",
    "\n",
    "f1model.fit(f1x, f1y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033194171442887832"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1model.score(f1x, f1y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.74021554040671822, 0.0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(np.log(threshold_df_agg.user_distinct_products), threshold_df_agg.user_ump_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df.loc[df.eval_set == 'test', ['order_id', 'product_id', 'user_distinct_products', 'model_prediction', 'p_not']].copy()\n",
    "df_test['reorder_cutoff'] = best_reorder_cutoff[0] + best_reorder_cutoff[1] * np.log(df_test.user_distinct_products)\n",
    "df_test['prediction'] = 1 * (df_test['model_prediction'] > df_test.reorder_cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14079389368571152"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writenone_df = test_df.groupby('order_id').agg({'putnone': np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writenone_df['nonestring'] = ''\n",
    "writenone_df.loc[writenone_df.putnone == 1, 'nonestring'] = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     75000\n",
       "unique        2\n",
       "top            \n",
       "freq      61594\n",
       "Name: nonestring, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writenone_df.nonestring.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_df = test_df.query('prediction == 1').copy()\n",
    "prediction_df = prediction_df[['order_id', 'product_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_lists = prediction_df.groupby('order_id').agg(lambda x: \" \".join(x.astype(str))).reset_index()\n",
    "prediction_lists = prediction_lists.merge(writenone_df[['order_id', 'nonestring']], on='order_id', how='right')\n",
    "prediction_lists['products'] = prediction_lists.product_id.fillna('')\n",
    "prediction_lists['products'] = prediction_lists.products + \" \" + prediction_lists.nonestring\n",
    "\n",
    "prediction_lists = prediction_lists[['order_id', 'products']]\n",
    "prediction_lists.to_csv(\"submissions/rawpredictions_composite.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>47766 38777 21463 13107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>13176 21137 47792 47766 43504 39475 2596 18618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>41787 24852 25890 5134 38689 2326 23794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>47209 39275 47672 33000 13629 41149 11520 9337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257</td>\n",
       "      <td>49235 24852 27966 21137 45013 27104 4605 37646...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                           products\n",
       "0        17                           47766 38777 21463 13107 \n",
       "1        34  13176 21137 47792 47766 43504 39475 2596 18618...\n",
       "2       137           41787 24852 25890 5134 38689 2326 23794 \n",
       "3       182  47209 39275 47672 33000 13629 41149 11520 9337...\n",
       "4       257  49235 24852 27966 21137 45013 27104 4605 37646..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_lists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
